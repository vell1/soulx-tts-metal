import os
import json
import time
import torch
import gradio as gr
import soundfile as sf
import io
import numpy as np
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
from pydantic import BaseModel

# å¯¼å…¥ SoulX-Podcast æ¨¡å—ï¼ˆå·²é›†æˆåˆ°é¡¹ç›®ä¸­ï¼‰
from soulxpodcast.config import SamplingParams
from soulxpodcast.utils.parser import podcast_format_parser
from soulxpodcast.utils.infer_utils import initiate_model, process_single_input
from soulxpodcast.utils.podcast_utils import (
    auto_parse_script, 
    validate_script, 
    PodcastScript,
    create_example_script,
    create_example_json_script
)

# ============== FastAPI åº”ç”¨ ==============
app = FastAPI(title="SoulX Podcast TTS", description="åŸºäº SoulX-Podcast-1.7B çš„è¯­éŸ³åˆæˆæœåŠ¡")

# ============== é…ç½® ==============
MODEL_PATH = "pretrained_models/SoulX-Podcast-1.7B-dialect"  # æ–¹è¨€æ¨¡å‹è·¯å¾„
PROMPT_AUDIO_DIR = "prompt_audios"
SAMPLE_RATE = 24000  # å®˜æ–¹é‡‡æ ·ç‡
SEED = 1988

# ============== è‡ªåŠ¨æ‰«æå‚è€ƒéŸ³é¢‘ ==============
def scan_prompt_audios():
    """
    è‡ªåŠ¨æ‰«æ prompt_audios ç›®å½•ä¸­çš„éŸ³é¢‘æ–‡ä»¶
    
    æ–‡ä»¶å‘½åè§„èŒƒ:
    - female_1.wav -> å¥³å£°1
    - male_1.wav -> ç”·å£°1
    - female_sweet.wav -> å¥³å£°sweet
    - è‡ªå®šä¹‰åç§°.wav -> è‡ªå®šä¹‰åç§°
    
    Returns:
        dict: è¯´è¯äººé…ç½®å­—å…¸
    """
    speakers = {}
    
    if not os.path.exists(PROMPT_AUDIO_DIR):
        print(f"[WARNING] å‚è€ƒéŸ³é¢‘ç›®å½•ä¸å­˜åœ¨: {PROMPT_AUDIO_DIR}")
        return speakers
    
    # æ‰«æç›®å½•ä¸­çš„ .wav æ–‡ä»¶
    audio_files = [f for f in os.listdir(PROMPT_AUDIO_DIR) 
                   if f.endswith('.wav') and not f.startswith('.')]
    
    if not audio_files:
        print(f"[WARNING] æœªæ‰¾åˆ°å‚è€ƒéŸ³é¢‘æ–‡ä»¶åœ¨: {PROMPT_AUDIO_DIR}")
        return speakers
    
    for audio_file in sorted(audio_files):
        # ç§»é™¤æ‰©å±•åè·å– ID
        speaker_id = audio_file[:-4]  # ç§»é™¤ .wav
        
        # ç”Ÿæˆå‹å¥½çš„æ˜¾ç¤ºåç§°
        display_name = generate_display_name(speaker_id)
        
        # è¯»å–éŸ³é¢‘æ–‡ä»¶çš„æ–‡æœ¬æè¿°ï¼ˆå¦‚æœæœ‰åŒå .txt æ–‡ä»¶ï¼‰
        txt_file = os.path.join(PROMPT_AUDIO_DIR, f"{speaker_id}.txt")
        if os.path.exists(txt_file):
            with open(txt_file, 'r', encoding='utf-8') as f:
                prompt_text = f.read().strip()
        else:
            # é»˜è®¤æ–‡æœ¬
            prompt_text = f"è¿™æ˜¯{display_name}çš„å‚è€ƒéŸ³é¢‘ã€‚"
        
        speakers[display_name] = {
            "id": speaker_id,
            "audio": os.path.join(PROMPT_AUDIO_DIR, audio_file),
            "text": prompt_text
        }
    
    print(f"[INFO] å·²æ‰«æåˆ° {len(speakers)} ä¸ªè¯´è¯äºº: {', '.join(speakers.keys())}")
    return speakers


def generate_display_name(speaker_id):
    """
    æ ¹æ®æ–‡ä»¶åç”Ÿæˆå‹å¥½çš„æ˜¾ç¤ºåç§°
    
    è§„åˆ™:
    - female_1 -> å¥³å£°1
    - male_1 -> ç”·å£°1
    - female_sweet -> å¥³å£°sweet
    - custom_name -> custom_name (ä¿æŒåŸæ ·)
    """
    # æ˜ å°„è¡¨
    prefix_map = {
        'female': 'å¥³å£°',
        'male': 'ç”·å£°',
        'neutral': 'ä¸­æ€§',
        'child': 'ç«¥å£°',
    }
    
    # å°è¯•åŒ¹é…å‰ç¼€
    for eng_prefix, cn_prefix in prefix_map.items():
        if speaker_id.startswith(eng_prefix + '_'):
            suffix = speaker_id[len(eng_prefix) + 1:]
            return f"{cn_prefix}{suffix}"
    
    # å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œè¿”å›åŸå§‹ ID
    return speaker_id


# è‡ªåŠ¨æ‰«æå¹¶åŠ è½½è¯´è¯äººé…ç½®
SPEAKERS = scan_prompt_audios()

# å¦‚æœæ²¡æœ‰æ‰«æåˆ°ä»»ä½•éŸ³é¢‘ï¼Œæä¾›é»˜è®¤é…ç½®
if not SPEAKERS:
    print("[WARNING] æœªæ‰¾åˆ°å‚è€ƒéŸ³é¢‘ï¼Œä½¿ç”¨ç©ºé…ç½®")
    SPEAKERS = {}

# æ–¹è¨€é…ç½®
DIALECTS = {
    "æ™®é€šè¯": {"code": "mandarin", "prefix": ""},
    "å››å·è¯": {"code": "sichuan", "prefix": "<|Sichuan|>"},
    "æ²³å—è¯": {"code": "henan", "prefix": "<|Henan|>"},
    "ç²¤è¯­": {"code": "yue", "prefix": "<|Yue|>"}
}

# ============== å…¨å±€æ¨¡å‹ ==============
model = None
dataset = None
audio_cache = {}  # ç¼“å­˜é¢„å¤„ç†çš„éŸ³é¢‘æ•°æ®
is_warmed_up = False  # æ¨¡å‹é¢„çƒ­æ ‡å¿—


def preload_reference_audios():
    """
    é¢„åŠ è½½å’Œç¼“å­˜æ‰€æœ‰å‚è€ƒéŸ³é¢‘
    
    é¿å…æ¯æ¬¡ç”Ÿæˆæ—¶é‡å¤åŠ è½½å’Œå¤„ç†ç›¸åŒçš„å‚è€ƒéŸ³é¢‘æ–‡ä»¶ã€‚
    """
    import time
    import torchaudio
    
    if not SPEAKERS:
        print("[WARNING] æ²¡æœ‰å¯ç”¨çš„è¯´è¯äººï¼Œè·³è¿‡éŸ³é¢‘é¢„åŠ è½½")
        return
    
    print("[INFO] ğŸµ é¢„åŠ è½½å‚è€ƒéŸ³é¢‘...")
    start_time = time.time()
    
    for speaker_name, speaker_config in SPEAKERS.items():
        audio_path = speaker_config["audio"]
        
        if not os.path.exists(audio_path):
            print(f"[WARNING] å‚è€ƒéŸ³é¢‘ä¸å­˜åœ¨: {audio_path}")
            continue
        
        try:
            # åŠ è½½éŸ³é¢‘
            waveform, sample_rate = torchaudio.load(audio_path)
            
            # é‡é‡‡æ ·åˆ° 24kHz
            if sample_rate != SAMPLE_RATE:
                resampler = torchaudio.transforms.Resample(sample_rate, SAMPLE_RATE)
                waveform = resampler(waveform)
            
            # è½¬æ¢ä¸ºå•å£°é“
            if waveform.shape[0] > 1:
                waveform = waveform.mean(dim=0, keepdim=True)
            
            # ç¼“å­˜æ³¢å½¢æ•°æ®
            audio_cache[speaker_name] = {
                "waveform": waveform,
                "sample_rate": SAMPLE_RATE,
                "text": speaker_config["text"],
                "path": audio_path
            }
            
            duration = waveform.shape[1] / SAMPLE_RATE
            print(f"  âœ“ {speaker_name}: {duration:.2f}s")
            
        except Exception as e:
            print(f"[ERROR] åŠ è½½ {speaker_name} å¤±è´¥: {e}")
    
    elapsed = time.time() - start_time
    print(f"[INFO] âœ… é¢„åŠ è½½å®Œæˆï¼å…± {len(audio_cache)} ä¸ªéŸ³é¢‘ï¼Œè€—æ—¶ {elapsed:.2f}s\n")


def warmup_model():
    """
    æ¨¡å‹é¢„çƒ­
    
    é¦–æ¬¡åŠ è½½åè¿è¡Œä¸€æ¬¡æ¨ç†ï¼Œé¿å…é¦–æ¬¡è¯·æ±‚æ—¶çš„é¢å¤–å»¶è¿Ÿã€‚
    """
    global is_warmed_up
    
    if is_warmed_up or not SPEAKERS:
        return
    
    print("[INFO] ğŸ”¥ æ¨¡å‹é¢„çƒ­ä¸­...")
    import time
    start_time = time.time()
    
    try:
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªè¯´è¯äººè¿›è¡Œé¢„çƒ­
        first_speaker = list(SPEAKERS.keys())[0]
        warmup_text = "ç³»ç»Ÿåˆå§‹åŒ–ã€‚"
        
        # æ‰§è¡Œä¸€æ¬¡å®Œæ•´æ¨ç†
        _ = generate_speech(warmup_text, first_speaker, "æ™®é€šè¯")
        
        elapsed = time.time() - start_time
        print(f"[INFO] âœ… é¢„çƒ­å®Œæˆï¼è€—æ—¶ {elapsed:.2f}s\n")
        is_warmed_up = True
        
    except Exception as e:
        print(f"[WARNING] æ¨¡å‹é¢„çƒ­å¤±è´¥: {e}\n")


def load_model():
    """åŠ è½½ SoulX-Podcast æ¨¡å‹ï¼ˆå•ä¾‹æ¨¡å¼ + é¢„åŠ è½½ä¼˜åŒ–ï¼‰"""
    global model, dataset
    
    if model is None:
        print("[INFO] æ­£åœ¨åŠ è½½ SoulX-Podcast æ¨¡å‹...")
        
        # æ£€æŸ¥æ¨¡å‹è·¯å¾„
        if not os.path.exists(MODEL_PATH):
            raise FileNotFoundError(
                f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {MODEL_PATH}\n"
                f"è¯·å…ˆä¸‹è½½æ¨¡å‹:\n"
                f"huggingface-cli download --resume-download Soul-AILab/SoulX-Podcast-1.7B-dialect "
                f"--local-dir {MODEL_PATH}"
            )
        
        # åˆå§‹åŒ–æ¨¡å‹
        model, dataset = initiate_model(
            seed=SEED,
            model_path=MODEL_PATH,
            llm_engine="hf",
            fp16_flow=False
        )
        
        print("[INFO] æ¨¡å‹åŠ è½½å®Œæˆï¼\n")
        
        # é¢„åŠ è½½å‚è€ƒéŸ³é¢‘ï¼ˆå¦‚æœè¿˜æ²¡åŠ è½½ï¼‰
        if not audio_cache:
            preload_reference_audios()
        
        # æ¨¡å‹é¢„çƒ­
        warmup_model()
    
    return model, dataset


def get_cached_audio(speaker_name: str):
    """
    è·å–ç¼“å­˜çš„éŸ³é¢‘æ•°æ®
    
    Args:
        speaker_name: è¯´è¯äººåç§°
    
    Returns:
        ç¼“å­˜çš„éŸ³é¢‘æ•°æ®ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› None
    """
    return audio_cache.get(speaker_name)


def preprocess_text(text: str) -> str:
    """
    é¢„å¤„ç†è¾“å…¥æ–‡æœ¬
    
    å¤„ç†å†…å®¹:
    1. å°†å¤šè¡Œæ–‡æœ¬åˆå¹¶ä¸ºå•è¡Œ
    2. ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
    3. ä¿ç•™æ ‡ç‚¹ç¬¦å·å’Œå‰¯è¯­è¨€æ ‡ç­¾
    
    Args:
        text: åŸå§‹æ–‡æœ¬
    
    Returns:
        å¤„ç†åçš„æ–‡æœ¬
    """
    # å°†æ¢è¡Œç¬¦æ›¿æ¢ä¸ºé€—å·ï¼ˆä¿æŒè¯­ä¹‰åˆ†éš”ï¼‰
    text = text.replace('\r\n', 'ï¼Œ')  # Windows æ¢è¡Œ
    text = text.replace('\n', 'ï¼Œ')    # Unix/Mac æ¢è¡Œ
    text = text.replace('\r', 'ï¼Œ')    # æ—§ Mac æ¢è¡Œ
    
    # ç§»é™¤è¿ç»­çš„é€—å·
    while 'ï¼Œï¼Œ' in text:
        text = text.replace('ï¼Œï¼Œ', 'ï¼Œ')
    
    # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦ï¼ˆä½†ä¿ç•™å‰¯è¯­è¨€æ ‡ç­¾ä¸­çš„å†…å®¹ï¼‰
    import re
    # ä¿æŠ¤å‰¯è¯­è¨€æ ‡ç­¾
    tags = re.findall(r'<\|[^|]+\|>', text)
    for i, tag in enumerate(tags):
        text = text.replace(tag, f'__TAG_{i}__')
    
    # ç§»é™¤å¤šä½™ç©ºç™½
    text = ' '.join(text.split())
    
    # æ¢å¤å‰¯è¯­è¨€æ ‡ç­¾
    for i, tag in enumerate(tags):
        text = text.replace(f'__TAG_{i}__', tag)
    
    # ç§»é™¤é¦–å°¾é€—å·å’Œç©ºæ ¼
    text = text.strip('ï¼Œ').strip()
    
    return text


def generate_speech(text: str, speaker: str, dialect: str):
    """
    ç”Ÿæˆè¯­éŸ³
    
    Args:
        text: è¾“å…¥æ–‡æœ¬ï¼ˆæ”¯æŒå¤šè¡Œï¼‰
        speaker: è¯´è¯äººåç§°ï¼ˆå¦‚ "å¥³å£°1"ï¼‰
        dialect: æ–¹è¨€åç§°ï¼ˆå¦‚ "æ™®é€šè¯"ï¼‰
    
    Returns:
        audio_array: éŸ³é¢‘æ•°æ® (numpy array)
    """
    # é¢„å¤„ç†æ–‡æœ¬
    text = preprocess_text(text)
    
    if not text:
        raise ValueError("æ–‡æœ¬å†…å®¹ä¸ºç©º")
    
    print(f"[INFO] å¤„ç†åçš„æ–‡æœ¬: {text[:100]}{'...' if len(text) > 100 else ''}")
    
    # åŠ è½½æ¨¡å‹
    model, dataset = load_model()
    
    # è·å–è¯´è¯äººé…ç½®
    speaker_config = SPEAKERS.get(speaker)
    if not speaker_config:
        raise ValueError(f"æœªçŸ¥è¯´è¯äºº: {speaker}")
    
    # è·å–æ–¹è¨€é…ç½®
    dialect_config = DIALECTS.get(dialect)
    if not dialect_config:
        raise ValueError(f"æœªçŸ¥æ–¹è¨€: {dialect}")
    
    dialect_prefix = dialect_config["prefix"]
    use_dialect_prompt = len(dialect_prefix) > 0
    
    # æ„å»ºè¾“å…¥æ•°æ®ï¼ˆæŒ‰ç…§å®˜æ–¹æ ¼å¼ï¼‰
    if use_dialect_prompt:
        # æ–¹è¨€æ¨¡å¼ï¼šéœ€è¦ dialect_prompt
        inputs_dict = {
            "speakers": {
                "S1": {
                    "prompt_audio": speaker_config["audio"],
                    "prompt_text": speaker_config["text"],
                    "dialect_prompt": f"{dialect_prefix}{speaker_config['text']}"
                }
            },
            "text": [
                ["S1", f"{dialect_prefix}{text}"]
            ]
        }
    else:
        # æ™®é€šè¯æ¨¡å¼ï¼šä¸éœ€è¦ dialect_prompt
        inputs_dict = {
            "speakers": {
                "S1": {
                    "prompt_audio": speaker_config["audio"],
                    "prompt_text": speaker_config["text"]
                }
            },
            "text": [
                ["S1", text]
            ]
        }
    
    import time
    
    # ========== é˜¶æ®µ 1: è§£æè¾“å…¥ ==========
    stage_start = time.time()
    inputs = podcast_format_parser(inputs_dict)
    parse_time = time.time() - stage_start
    print(f"[PERF] è¾“å…¥è§£æ: {parse_time:.3f}s")
    
    # ========== é˜¶æ®µ 2: é¢„å¤„ç†æ•°æ®ï¼ˆCPUå¯†é›†ï¼‰==========
    stage_start = time.time()
    data = process_single_input(
        dataset,
        inputs['text'],
        inputs['prompt_wav'],
        inputs['prompt_text'],
        inputs['use_dialect_prompt'],
        inputs['dialect_prompt_text'],
    )
    preprocess_time = time.time() - stage_start
    print(f"[PERF] æ•°æ®é¢„å¤„ç†ï¼ˆéŸ³é¢‘tokenizationï¼‰: {preprocess_time:.3f}s [CPU]")
    
    # ========== é˜¶æ®µ 3: æ¨¡å‹æ¨ç†ï¼ˆGPUåŠ é€Ÿï¼‰==========
    stage_start = time.time()
    print(f"[INFO] å¼€å§‹ç”Ÿæˆè¯­éŸ³...")
    results_dict = model.forward_longform(**data)
    inference_time = time.time() - stage_start
    print(f"[PERF] æ¨¡å‹æ¨ç†ï¼ˆLLM+Flow+Vocoderï¼‰: {inference_time:.3f}s [GPU]")
    
    # ========== é˜¶æ®µ 4: åå¤„ç† ==========
    stage_start = time.time()
    target_audio = None
    for wav in results_dict["generated_wavs"]:
        if target_audio is None:
            target_audio = wav
        else:
            target_audio = torch.cat([target_audio, wav], dim=1)
    
    # è½¬æ¢ä¸º numpy æ•°ç»„
    audio_array = target_audio.cpu().squeeze(0).numpy()
    postprocess_time = time.time() - stage_start
    print(f"[PERF] åå¤„ç†: {postprocess_time:.3f}s")
    
    # æ€»ç»“
    total_time = parse_time + preprocess_time + inference_time + postprocess_time
    audio_duration = len(audio_array) / SAMPLE_RATE
    rtf = total_time / audio_duration  # Real-Time Factor
    print(f"[INFO] âœ… ç”Ÿæˆå®Œæˆï¼éŸ³é¢‘: {audio_duration:.2f}s | è€—æ—¶: {total_time:.2f}s | RTF: {rtf:.2f}x")
    
    return audio_array


def generate_multiperson_podcast(script: PodcastScript, silence_duration: float = 0.5):
    """
    ç”Ÿæˆå¤šäººæ’­å®¢
    
    Args:
        script: æ’­å®¢è„šæœ¬å¯¹è±¡
        silence_duration: å¯¹è¯ä¹‹é—´çš„é™éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰
    
    Returns:
        audio_array: å®Œæ•´çš„æ’­å®¢éŸ³é¢‘ (numpy array)
    """
    import time
    
    print("=" * 60)
    print("ğŸ™ï¸  å¼€å§‹ç”Ÿæˆå¤šäººæ’­å®¢")
    print("=" * 60)
    
    total_start = time.time()
    
    # éªŒè¯è„šæœ¬
    is_valid, error_msg = validate_script(script, list(SPEAKERS.keys()))
    if not is_valid:
        raise ValueError(f"è„šæœ¬éªŒè¯å¤±è´¥: {error_msg}")
    
    print(f"[INFO] è§’è‰²æ•°é‡: {len(script.speakers)}")
    print(f"[INFO] å¯¹è¯æ•°é‡: {len(script.dialogues)}")
    for name, config in script.speakers.items():
        print(f"  - {name}: {config['voice']} ({config['dialect']})")
    print()
    
    # ç”Ÿæˆé™éŸ³ç‰‡æ®µ
    silence_samples = int(SAMPLE_RATE * silence_duration)
    silence = np.zeros(silence_samples, dtype=np.float32)
    
    # å­˜å‚¨æ‰€æœ‰éŸ³é¢‘ç‰‡æ®µ
    audio_segments = []
    
    # é€ä¸ªç”Ÿæˆå¯¹è¯
    for i, dialogue in enumerate(script.dialogues, 1):
        speaker = dialogue["speaker"]
        text = dialogue["text"]
        
        speaker_config = script.speakers[speaker]
        voice = speaker_config["voice"]
        dialect = speaker_config["dialect"]
        
        print(f"[{i}/{len(script.dialogues)}] ç”Ÿæˆä¸­: [{speaker}] {text[:50]}{'...' if len(text) > 50 else ''}")
        
        try:
            # ç”Ÿæˆå•å¥è¯­éŸ³
            audio = generate_speech(text, voice, dialect)
            audio_segments.append(audio)
            
            # æ·»åŠ é™éŸ³ï¼ˆé™¤äº†æœ€åä¸€å¥ï¼‰
            if i < len(script.dialogues):
                audio_segments.append(silence)
            
            print(f"  âœ“ å®Œæˆï¼éŸ³é¢‘æ—¶é•¿: {len(audio)/SAMPLE_RATE:.2f}s\n")
            
        except Exception as e:
            print(f"  âœ— ç”Ÿæˆå¤±è´¥: {e}\n")
            raise
    
    # åˆå¹¶æ‰€æœ‰éŸ³é¢‘ç‰‡æ®µ
    print("[INFO] åˆå¹¶éŸ³é¢‘ç‰‡æ®µ...")
    final_audio = np.concatenate(audio_segments)
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_time = time.time() - total_start
    total_duration = len(final_audio) / SAMPLE_RATE
    
    print("=" * 60)
    print("âœ… å¤šäººæ’­å®¢ç”Ÿæˆå®Œæˆï¼")
    print(f"  - æ€»æ—¶é•¿: {total_duration:.2f}s")
    print(f"  - è€—æ—¶: {total_time:.2f}s")
    print(f"  - å¹³å‡é€Ÿåº¦: {total_duration/total_time:.2f}x å®æ—¶")
    print("=" * 60)
    
    return final_audio


# ============== REST API ==============
class TTSRequest(BaseModel):
    text: str
    speaker: str = "å¥³å£°1"
    dialect: str = "æ™®é€šè¯"


class PodcastRequest(BaseModel):
    script: str  # è„šæœ¬æ–‡æœ¬ï¼ˆç®€å•æ ¼å¼æˆ– JSON æ ¼å¼ï¼‰
    silence_duration: float = 0.5  # å¯¹è¯é—´éš”ï¼ˆç§’ï¼‰


@app.post("/api/tts")
def api_tts(req: TTSRequest):
    """REST API æ¥å£ï¼šæ–‡æœ¬è½¬è¯­éŸ³ï¼ˆå•äººï¼‰"""
    try:
        audio_array = generate_speech(req.text, req.speaker, req.dialect)

        # å†™å…¥ WAV æ ¼å¼
        buf = io.BytesIO()
        sf.write(buf, audio_array, SAMPLE_RATE, format="wav")
        buf.seek(0)
        
        return StreamingResponse(buf, media_type="audio/wav")

    except Exception as e:
        return {"error": str(e)}


@app.post("/api/podcast")
def api_podcast(req: PodcastRequest):
    """REST API æ¥å£ï¼šå¤šäººæ’­å®¢ç”Ÿæˆ"""
    try:
        # è§£æè„šæœ¬
        script = auto_parse_script(req.script)
        
        # ç”Ÿæˆæ’­å®¢
        audio_array = generate_multiperson_podcast(script, req.silence_duration)
        
        # å†™å…¥ WAV æ ¼å¼
        buf = io.BytesIO()
        sf.write(buf, audio_array, SAMPLE_RATE, format="wav")
        buf.seek(0)
        
        return StreamingResponse(buf, media_type="audio/wav")
    
    except Exception as e:
        return {"error": str(e)}


@app.get("/api/podcast/example")
def api_podcast_example(format: str = "simple"):
    """
    è·å–ç¤ºä¾‹è„šæœ¬
    
    Args:
        format: è„šæœ¬æ ¼å¼ ("simple" æˆ– "json")
    """
    if format == "json":
        return {
            "format": "json",
            "script": create_example_json_script()
        }
    else:
        return {
            "format": "simple",
            "script": create_example_script()
        }


# ============== Gradio Web ç•Œé¢ ==============
def tts_web(text, speaker, dialect):
    """Gradio ç•Œé¢çš„ TTS å‡½æ•°ï¼ˆå•äººï¼‰"""
    try:
        if not text or len(text.strip()) == 0:
            return None, "è¯·è¾“å…¥æ–‡æœ¬ï¼"
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        
        audio_array = generate_speech(text, speaker, dialect)
        
        # è®¡ç®—è€—æ—¶
        elapsed_time = time.time() - start_time
        
        # è®¡ç®—éŸ³é¢‘æ—¶é•¿
        audio_duration = len(audio_array) / SAMPLE_RATE
        
        # Gradio è¿”å›æ ¼å¼: (sample_rate, audio_array)
        status_msg = f"âœ… ç”ŸæˆæˆåŠŸï¼\nâ±ï¸ è€—æ—¶: {elapsed_time:.2f} ç§’\nğŸµ éŸ³é¢‘æ—¶é•¿: {audio_duration:.2f} ç§’"
        return (SAMPLE_RATE, audio_array), status_msg
    
    except Exception as e:
        return None, f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}"


def podcast_web(script_text, silence_duration):
    """Gradio ç•Œé¢çš„å¤šäººæ’­å®¢ç”Ÿæˆå‡½æ•°"""
    try:
        if not script_text or len(script_text.strip()) == 0:
            return None, "è¯·è¾“å…¥æ’­å®¢è„šæœ¬ï¼"
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        
        # è§£æè„šæœ¬
        script = auto_parse_script(script_text)
        
        # ç”Ÿæˆæ’­å®¢
        audio_array = generate_multiperson_podcast(script, silence_duration)
        
        # è®¡ç®—è€—æ—¶
        elapsed_time = time.time() - start_time
        
        # è®¡ç®—éŸ³é¢‘æ—¶é•¿
        audio_duration = len(audio_array) / SAMPLE_RATE
        
        # ç»Ÿè®¡å¯¹è¯æ•°é‡
        dialogue_count = len(script.dialogues)
        speaker_count = len(script.speakers)
        
        # Gradio è¿”å›æ ¼å¼: (sample_rate, audio_array)
        status_msg = (
            f"âœ… æ’­å®¢ç”ŸæˆæˆåŠŸï¼\n"
            f"â±ï¸ æ€»è€—æ—¶: {elapsed_time:.2f} ç§’\n"
            f"ğŸµ éŸ³é¢‘æ—¶é•¿: {audio_duration:.2f} ç§’\n"
            f"ğŸ‘¥ å‚ä¸è€…: {speaker_count} äºº\n"
            f"ğŸ’¬ å¯¹è¯æ•°: {dialogue_count} æ®µ"
        )
        return (SAMPLE_RATE, audio_array), status_msg
    
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        return None, f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}\n\nè¯¦ç»†é”™è¯¯:\n{error_detail}"


# åˆ›å»º Gradio ç•Œé¢
with gr.Blocks(title="SoulX Podcast TTS", theme=gr.themes.Soft()) as gr_app:
    gr.Markdown("""
    # ğŸ™ï¸ SoulX Podcast TTS
    
    åŸºäº **SoulX-Podcast-1.7B-dialect** æ¨¡å‹çš„é«˜è´¨é‡è¯­éŸ³åˆæˆæœåŠ¡
    
    âœ¨ æ”¯æŒå•äººè¯­éŸ³ã€å¤šäººæ’­å®¢ã€å¤šæ–¹è¨€ã€é›¶æ ·æœ¬å£°éŸ³å…‹éš†
    """)
    
    with gr.Tabs():
        # ========== å•äººè¯­éŸ³ç”Ÿæˆ ==========
        with gr.Tab("ğŸ¤ å•äººè¯­éŸ³"):
            with gr.Row():
                with gr.Column(scale=2):
                    text_input = gr.Textbox(
                        label="è¾“å…¥æ–‡æœ¬",
                        placeholder="è¯·è¾“å…¥è¦è½¬æ¢çš„æ–‡æœ¬...\n\næ”¯æŒå‰¯è¯­è¨€æ ‡ç­¾ï¼š<|laughter|> (ç¬‘å£°)ã€<|sigh|> (å¹æ°”)ã€<|breathing|> (å‘¼å¸)ã€<|coughing|> (å’³å—½)",
                        lines=5
                    )
                    
                    with gr.Row():
                        speaker_dropdown = gr.Dropdown(
                            choices=list(SPEAKERS.keys()),
                            value="å¥³å£°1" if SPEAKERS else None,
                            label="è¯´è¯äºº"
                        )
                        
                        dialect_dropdown = gr.Dropdown(
                            choices=list(DIALECTS.keys()),
                            value="æ™®é€šè¯",
                            label="æ–¹è¨€"
                        )
                    
                    generate_btn = gr.Button("ğŸµ ç”Ÿæˆè¯­éŸ³", variant="primary", size="lg")
                
                with gr.Column(scale=1):
                    status_text = gr.Textbox(label="çŠ¶æ€", value="å°±ç»ª", lines=4)
                    audio_output = gr.Audio(label="ç”Ÿæˆçš„è¯­éŸ³", type="numpy")
            
            # äº‹ä»¶ç»‘å®š
            generate_btn.click(
                fn=tts_web,
                inputs=[text_input, speaker_dropdown, dialect_dropdown],
                outputs=[audio_output, status_text]
            )
        
        # ========== å¤šäººæ’­å®¢ç”Ÿæˆ ==========
        with gr.Tab("ğŸ™ï¸ å¤šäººæ’­å®¢"):
            with gr.Row():
                with gr.Column(scale=2):
                    gr.Markdown("""
                    ### ğŸ“ æ’­å®¢è„šæœ¬æ ¼å¼è¯´æ˜
                    
                    **ç®€å•æ ¼å¼ç¤ºä¾‹ï¼š**
                    ```
                    # è§’è‰²å®šä¹‰
                    @è§’è‰²: ä¸»æŒäºº, å¥³å£°1, æ™®é€šè¯
                    @è§’è‰²: å˜‰å®¾, ç”·å£°1, æ™®é€šè¯
                    
                    # å¯¹è¯å†…å®¹
                    [ä¸»æŒäºº]: å¤§å®¶å¥½ï¼Œæ¬¢è¿æ”¶å¬ä»Šå¤©çš„èŠ‚ç›®ï¼
                    [å˜‰å®¾]: ä½ å¥½ï¼Œå¾ˆé«˜å…´æ¥åˆ°è¿™é‡Œã€‚
                    ```
                    
                    **æ”¯æŒå‰¯è¯­è¨€æ ‡ç­¾:** `<|laughter|>` (ç¬‘å£°)ã€`<|sigh|>` (å¹æ°”) ç­‰
                    """)
                    
                    script_input = gr.Textbox(
                        label="æ’­å®¢è„šæœ¬",
                        placeholder="åœ¨æ­¤è¾“å…¥æ’­å®¢è„šæœ¬...\næˆ–ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®åŠ è½½ç¤ºä¾‹è„šæœ¬",
                        lines=15,
                        value=""
                    )
                    
                    with gr.Row():
                        load_example_btn = gr.Button("ğŸ“„ åŠ è½½ç¤ºä¾‹è„šæœ¬", size="sm")
                        clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©º", size="sm")
                    
                    silence_slider = gr.Slider(
                        minimum=0.1,
                        maximum=2.0,
                        value=0.5,
                        step=0.1,
                        label="å¯¹è¯é—´éš”ï¼ˆç§’ï¼‰",
                        info="å¯¹è¯ä¹‹é—´çš„é™éŸ³æ—¶é•¿"
                    )
                    
                    generate_podcast_btn = gr.Button("ğŸ™ï¸ ç”Ÿæˆæ’­å®¢", variant="primary", size="lg")
                
                with gr.Column(scale=1):
                    podcast_status = gr.Textbox(label="çŠ¶æ€", value="å°±ç»ª", lines=6)
                    podcast_audio = gr.Audio(label="ç”Ÿæˆçš„æ’­å®¢", type="numpy")
            
            # äº‹ä»¶ç»‘å®š
            generate_podcast_btn.click(
                fn=podcast_web,
                inputs=[script_input, silence_slider],
                outputs=[podcast_audio, podcast_status]
            )
            
            load_example_btn.click(
                fn=lambda: create_example_script(),
                inputs=[],
                outputs=[script_input]
            )
            
            clear_btn.click(
                fn=lambda: "",
                inputs=[],
                outputs=[script_input]
            )
            
            gr.Markdown("""
            ### ğŸ’¡ ä½¿ç”¨æç¤º
            
            1. **å®šä¹‰è§’è‰²**: ä½¿ç”¨ `@è§’è‰²: åç§°, å£°éŸ³, æ–¹è¨€` æ ¼å¼å®šä¹‰å‚ä¸è€…
            2. **ç¼–å†™å¯¹è¯**: ä½¿ç”¨ `[è§’è‰²å]: å¯¹è¯å†…å®¹` æ ¼å¼ç¼–å†™å¯¹è¯
            3. **æ·»åŠ æƒ…æ„Ÿ**: åœ¨å¯¹è¯ä¸­æ’å…¥å‰¯è¯­è¨€æ ‡ç­¾ï¼Œå¦‚ `<|laughter|>` å¢å¼ºè¡¨ç°åŠ›
            4. **è°ƒæ•´é—´éš”**: æ ¹æ®éœ€è¦è°ƒæ•´å¯¹è¯ä¹‹é—´çš„é™éŸ³æ—¶é•¿
            
            **å¯ç”¨å£°éŸ³ï¼š** """ + ", ".join(SPEAKERS.keys() if SPEAKERS else ["è¯·å…ˆé…ç½®å‚è€ƒéŸ³é¢‘"]) + """
            
            **å¯ç”¨æ–¹è¨€ï¼š** """ + ", ".join(DIALECTS.keys()) + """
            """)
    
    gr.Markdown("""
    ---
    ### ğŸ“š API è°ƒç”¨ç¤ºä¾‹
    
    **å•äººè¯­éŸ³ç”Ÿæˆ:**
    ```bash
    curl -X POST http://localhost:8000/api/tts \\
      -H "Content-Type: application/json" \\
      -d '{"text": "ä½ å¥½ï¼Œæ¬¢è¿æ¥åˆ° SoulX æ’­å®¢ï¼", "speaker": "å¥³å£°1", "dialect": "æ™®é€šè¯"}' \\
      --output output.wav
    ```
    
    **å¤šäººæ’­å®¢ç”Ÿæˆ:**
    ```bash
    curl -X POST http://localhost:8000/api/podcast \\
      -H "Content-Type: application/json" \\
      -d '{
        "script": "# è§’è‰²å®šä¹‰\\n@è§’è‰²: ä¸»æŒäºº, å¥³å£°1, æ™®é€šè¯\\n@è§’è‰²: å˜‰å®¾, ç”·å£°1, æ™®é€šè¯\\n\\n[ä¸»æŒäºº]: å¤§å®¶å¥½ï¼\\n[å˜‰å®¾]: ä½ å¥½ï¼",
        "silence_duration": 0.5
      }' \\
      --output podcast.wav
    ```
    
    **è·å–ç¤ºä¾‹è„šæœ¬:**
    ```bash
    curl http://localhost:8000/api/podcast/example?format=simple
    ```
    
    ---
    **æ¨¡å‹**: [SoulX-Podcast-1.7B-dialect](https://huggingface.co/Soul-AILab/SoulX-Podcast-1.7B-dialect) | 
    **é¡¹ç›®**: [GitHub](https://github.com/Soul-AILab/SoulX-Podcast)
    """)

# æŒ‚è½½ Gradio åˆ° FastAPI
app = gr.mount_gradio_app(app, gr_app, path="/")

if __name__ == "__main__":
    import uvicorn
    print("=" * 60)
    print("ğŸ™ï¸  SoulX Podcast TTS æœåŠ¡å¯åŠ¨ä¸­...")
    print("=" * 60)
    print(f"ğŸ“‚ æ¨¡å‹è·¯å¾„: {MODEL_PATH}")
    print(f"ğŸµ é‡‡æ ·ç‡: {SAMPLE_RATE} Hz")
    print(f"ğŸŒ è®¿é—®åœ°å€: http://localhost:8000")
    print("=" * 60)
    
    uvicorn.run(app, host="0.0.0.0", port=8000)
